{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7IwNk_aZoOF"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import colorsys\n",
        "import argparse\n",
        "import time\n",
        "from mask_rcnn.object_detection import visualization_utils\n",
        "from samples.coco.coco import CocoConfig\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvexQQ0aaiu1"
      },
      "source": [
        "class MyConfig(CocoConfig):\n",
        "    NAME = \"my_coco_inference\"\n",
        "    # Set batch size to 1 since we'll be running inference on one image at a time.\n",
        "    # Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FszHMfuLanGr"
      },
      "source": [
        "def prepare_mrcnn_model(model_path, model_name, class_names, my_config):\n",
        "    classes = open(class_names).read().strip().split(\"\\n\")\n",
        "    print(\"No. of classes\", len(classes))\n",
        "\n",
        "    hsv = [(i / len(classes), 1, 1.0) for i in range(len(classes))]\n",
        "    COLORS = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.seed(42)\n",
        "    random.shuffle(COLORS)\n",
        "\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=model_path, config=my_config)\n",
        "    model.load_weights(model_name, by_name=True)\n",
        "\n",
        "    return COLORS, model, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dATfcs_ap7r"
      },
      "source": [
        "def custom_visualize(test_image, model, colors, classes, draw_bbox, mrcnn_visualize, instance_segmentation):\n",
        "    detections = model.detect([test_image], verbose=1)[0]\n",
        "\n",
        "    if mrcnn_visualize:\n",
        "        matplotlib.use('TkAgg')\n",
        "        visualize.display_instances(test_image, detections['rois'], detections['masks'], detections['class_ids'], classes, detections['scores'])\n",
        "        return\n",
        "\n",
        "    if instance_segmentation:\n",
        "        hsv = [(i / len(detections['rois']), 1, 1.0) for i in range(len(detections['rois']))]\n",
        "        colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "        random.seed(42)\n",
        "        random.shuffle(colors)\n",
        "\n",
        "    for i in range(0, detections[\"rois\"].shape[0]):\n",
        "        classID = detections[\"class_ids\"][i]\n",
        "\n",
        "        mask = detections[\"masks\"][:, :, i]\n",
        "        if instance_segmentation:\n",
        "            color = colors[i][::-1]\n",
        "        else:\n",
        "            color = colors[classID][::-1]\n",
        "\n",
        "        # To visualize the pixel-wise mask of the object\n",
        "        test_image = visualize.apply_mask(test_image, mask, color, alpha=0.5)\n",
        "\n",
        "    test_image = cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    if draw_bbox:\n",
        "        for i in range(0, len(detections[\"scores\"])):\n",
        "            (startY, startX, endY, endX) = detections[\"rois\"][i]\n",
        "\n",
        "            classID = detections[\"class_ids\"][i]\n",
        "            label = classes[classID]\n",
        "            score = detections[\"scores\"][i]\n",
        "\n",
        "            if instance_segmentation:\n",
        "                color = [int(c) for c in np.array(colors[i]) * 255]\n",
        "\n",
        "            else:\n",
        "                color = [int(c) for c in np.array(colors[classID]) * 255]\n",
        "\n",
        "            cv2.rectangle(test_image, (startX, startY), (endX, endY), color, 2)\n",
        "            text = \"{}: {:.2f}\".format(label, score)\n",
        "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "            cv2.putText(test_image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    return test_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4HoMgPwa0ZU"
      },
      "source": [
        "def perform_inference_image(image_path, model, colors, classes, draw_bbox, mrcnn_visualize, instance_segmentation, save_enable):\n",
        "    test_image = cv2.imread(image_path)\n",
        "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    output = custom_visualize(test_image, model, colors, classes, draw_bbox, mrcnn_visualize, instance_segmentation)\n",
        "    if not mrcnn_visualize:\n",
        "        if save_enable:\n",
        "            cv2.imwrite(\"result.png\", output)\n",
        "        cv2.imshow(\"Output\", output)\n",
        "        cv2.waitKey()\n",
        "        cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80JhYOmha1Db"
      },
      "source": [
        "def perform_inference_video(use_camera, video_path, model, colors, classes, draw_bbox, mrcnn_visualize,\n",
        "                            instance_segmentation, save_enable):\n",
        "    if use_camera:\n",
        "        video = cv2.VideoCapture(0)\n",
        "        time.sleep(2.0)\n",
        "    else:\n",
        "        video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    video_flag = True\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "\n",
        "        if save_enable and video_flag:\n",
        "            out = cv2.VideoWriter(\"Result_Video.mp4\", cv2.VideoWriter_fourcc(*'MP4V'), 8,\n",
        "                                  (frame.shape[1], frame.shape[0]))\n",
        "            video_flag = False\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        output = custom_visualize(frame, model, colors, classes, draw_bbox, mrcnn_visualize, instance_segmentation)\n",
        "\n",
        "        cv2.imshow(\"Output\", output)\n",
        "\n",
        "        if save_enable:\n",
        "            out.write(output)\n",
        "\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        if key == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    video.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}